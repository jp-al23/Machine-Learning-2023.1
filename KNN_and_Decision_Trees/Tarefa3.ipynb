{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Inicializar",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom math import sqrt, exp, log, pi\nfrom scipy import stats as st # calcular a moda de um array\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import recall_score, precision_score, f1_score\n\ndef k_fold(X, Y, k):\n    n,m = X.shape\n    ordenacao = np.arange(n)\n    np.random.shuffle(ordenacao)\n    saida = []\n    intervalo = n // k\n    grupos_X = []\n    grupos_Y = []\n    for i in range(k):\n        grupos_X.append( X[ordenacao % k == i] )\n        grupos_Y.append( Y[ordenacao % k == i] )\n\n    return grupos_X, grupos_Y\n\ndef matriz_desvios(x, media):\n    desvio = np.atleast_2d(x-media)\n    matriz_dev = desvio.T @ desvio\n    return matriz_dev\n  \ndef gerar_mat_cov(X):\n    n, p = X.shape\n    media = np.mean(X, axis=0)\n    vetor_matrizes = np.array([ matriz_desvios(X[i], media) for i in range(n)])\n    return np.sum(vetor_matrizes, axis = 0) / (n-1)\n\ndef criar_acuracias(y_pred, y_real, K):\n    y_pred = np.atleast_2d(y_pred)\n    if y_pred.shape[1] == 1: y_pred = y_pred.T\n    y_real = np.atleast_2d(y_real)\n    if y_real.shape[1] == 1: y_real = y_real.T\n    \n    \n    iguais = y_pred == y_real\n    n = y_real.shape[1]\n    acuracia_global = np.sum(iguais) / n\n    acuracia_grupos = []\n    for i in range(K):\n        acuracia_grupos.append( np.sum( iguais[y_real == i]) / np.sum(y_real == i))\n    return (acuracia_global, acuracia_grupos)\n    \n\ndef dist_euclidiana(x1, x2):\n    x1 = np.atleast_2d(x1)\n    if x1.shape[1] == 1: x1 = x1.T\n    x2 = np.atleast_2d(x2)\n    if x2.shape[1] == 1: x2 = x2.T\n    \n    return  sqrt(np.sum((x1-x2)**2))\n\ndef dist_manhattan(x1, x2):\n    x1 = np.atleast_2d(x1)\n    if x1.shape[1] == 1: x1 = x1.T\n    x2 = np.atleast_2d(x2)\n    if x2.shape[1] == 1: x2 = x2.T\n    \n    return np.sum(np.abs(x1-x2))\n\ndef dist_mahalanobis(x1, x2, mat_cov):\n    x1 = np.atleast_2d(x1)\n    if x1.shape[1] == 1: x1 = x1.T\n    x2 = np.atleast_2d(x2)\n    if x2.shape[1] == 1: x2 = x2.T\n    \n    return sqrt( (x1-x2) @ mat_cov @ (x1-x2).T )  \n    ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# KNN",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def KNN(X_treino, X_teste, y_treino, K = 1, distancia = \"euclidiana\", mat_cov = None):\n    y_treino = np.atleast_2d(y_treino).astype(int)\n    if y_treino.shape[0] == 1: y_treino = y_treino.T\n    n, m = X_treino.shape\n    K = min(K, n)\n    \n    map_distancias = {\"euclidiana\" : dist_euclidiana, \"manhattan\": dist_manhattan, \"mahalanobis\": dist_mahalanobis} \n    d = map_distancias[distancia]\n    \n    ordenacoes_teste = []\n    for xi_teste in X_teste:\n        ordenacao_aux = []\n        for xi_treino in X_treino:\n            if distancia == \"mahalanobis\":\n                ordenacao_aux.append( d(xi_teste, xi_treino, mat_cov) )\n            else:\n                ordenacao_aux.append( d(xi_teste, xi_treino) )\n        ordenacoes_teste.append( np.argsort(np.array(ordenacao_aux)) )\n    ordenacoes_teste = np.array(ordenacoes_teste)\n    \n    escolhidos = y_treino[ ordenacoes_teste[:,:K] ]\n    y_pred, frequencia = st.mode(escolhidos, axis = 1, keepdims = False)\n    return y_pred.T",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Primeira Questão",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dataset_q1 = np.genfromtxt('./kc2.csv', delimiter=',')\ndataset_X = dataset_q1[:,:-1]\ndataset_Y = dataset_q1[:,-1].astype(int)\n\n\ngrupos_X, grupos_Y = k_fold(dataset_X, dataset_Y, 10)\nn_atribs = len(np.unique(dataset_Y))\n\n# KNN\nfor Ki, f_distancia in ( (1, \"euclidiana\"), (5, \"euclidiana\"), (1, \"mahalanobis\"), (5, \"mahalanobis\") ):\n    print(\"------------- \"+str(Ki)+\"-NN | \"+ f_distancia +\" -------------\")\n    array_acc_global = []\n    array_acc_grupos = []\n    array_revocacao = []\n    array_precisao = []\n    array_f1score = []\n    for k in range(10):\n        treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n        treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])\n        teste_X = grupos_X[k]\n        teste_Y = grupos_Y[k]\n        n = teste_X.shape[0]\n        matriz_covariancia = gerar_mat_cov(treino_X)\n\n        predicoes_Y = KNN(treino_X, teste_X, treino_Y, K = Ki, distancia = f_distancia, mat_cov = matriz_covariancia)\n\n        acc_global, acc_grupos = criar_acuracias(predicoes_Y, teste_Y, n_atribs)\n        revocacao = recall_score(teste_Y, predicoes_Y.T, average = None)\n        precisao = precision_score(teste_Y, predicoes_Y.T, average=None)\n        f1score = f1_score(teste_Y, predicoes_Y.T, average = None)\n        \n        array_acc_global.append(acc_global)\n        array_acc_grupos.append(acc_grupos)\n        array_revocacao.append(revocacao)\n        array_precisao.append(precisao)\n        array_f1score.append(f1score)\n\n    media_acc_global = np.mean( np.array(array_acc_global) )\n    dp_acc_global = np.std( np.array(array_acc_global) )\n\n    media_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\n    dp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\n\n    media_revocacao = np.mean( np.array(array_revocacao) , axis = 0)\n    dp_revocacao = np.std( np.array(array_revocacao) , axis = 0)\n\n    media_precisao = np.mean( np.array(array_precisao) , axis = 0)\n    dp_precisao = np.std( np.array(array_precisao) , axis = 0)\n\n    media_f1score = np.mean( np.array(array_f1score) , axis = 0)\n    dp_f1score = np.std( np.array(array_f1score) , axis = 0)\n\n    print(\"Valor médio acurácia global:\", media_acc_global)\n    print(\"Desvio Padrão acurácia global:\", dp_acc_global)\n    print()\n    print(\"Valor médio acurácia por grupo:\",media_acc_grupos)\n    print(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\n    print()\n    print(\"Valor médio revocação por grupo:\",media_revocacao)\n    print(\"Desvio Padrão revocação por grupo:\", dp_revocacao)\n    print()\n    print(\"Valor médio precisão por grupo:\",media_precisao)\n    print(\"Desvio Padrão precisão por grupo:\", dp_precisao)\n    print()\n    print(\"Valor médio f1_score por grupo:\",media_f1score)\n    print(\"Desvio Padrão f1_score por grupo:\", dp_f1score)\n    print()\n    print()\n    print()\n    \n    \n# Arvore de decisão\nprint(\"------------- Arvore de decisão | Gini -------------\")\narray_acc_global = []\narray_acc_grupos = []\narray_revocacao = []\narray_precisao = []\narray_f1score = []\nfor k in range(10):\n    treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n    treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])\n    teste_X = grupos_X[k]\n    teste_Y = grupos_Y[k]\n    n = teste_X.shape[0]\n\n    dtc_gini = DecisionTreeClassifier(criterion='gini')\n    dtc_gini.fit(treino_X, treino_Y)\n    predicoes_Y = dtc_gini.predict(teste_X)\n    \n    \n\n    acc_global, acc_grupos = criar_acuracias(predicoes_Y, teste_Y, n_atribs)\n    revocacao = recall_score(teste_Y, predicoes_Y, average = None)\n    precisao = precision_score(teste_Y, predicoes_Y, average=None)\n    f1score = f1_score(teste_Y, predicoes_Y, average = None)\n    \n    array_acc_global.append(acc_global)\n    array_acc_grupos.append(acc_grupos)\n    array_revocacao.append(revocacao)\n    array_precisao.append(precisao)\n    array_f1score.append(f1score)\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\ndp_acc_global = np.std( np.array(array_acc_global) )\n\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\n\nmedia_revocacao = np.mean( np.array(array_revocacao) , axis = 0)\ndp_revocacao = np.std( np.array(array_revocacao) , axis = 0)\n\nmedia_precisao = np.mean( np.array(array_precisao) , axis = 0)\ndp_precisao = np.std( np.array(array_precisao) , axis = 0)\n\nmedia_f1score = np.mean( np.array(array_f1score) , axis = 0)\ndp_f1score = np.std( np.array(array_f1score) , axis = 0)\n\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint()\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\nprint(\"Valor médio revocação por grupo:\",media_revocacao)\nprint(\"Desvio Padrão revocação por grupo:\", dp_revocacao)\nprint()\nprint(\"Valor médio precisão por grupo:\",media_precisao)\nprint(\"Desvio Padrão precisão por grupo:\", dp_precisao)\nprint()\nprint(\"Valor médio f1_score por grupo:\",media_f1score)\nprint(\"Desvio Padrão f1_score por grupo:\", dp_f1score)\nprint()\nprint()\nprint()\n\nprint(\"------------- Arvore de decisão | Entropia -------------\")\narray_acc_global = []\narray_acc_grupos = []\narray_revocacao = []\narray_precisao = []\narray_f1score = []\nfor k in range(10):\n    treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n    treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])\n    teste_X = grupos_X[k]\n    teste_Y = grupos_Y[k]\n    n = teste_X.shape[0]\n\n    dtc_entropy = DecisionTreeClassifier(criterion='entropy')\n    dtc_entropy.fit(treino_X, treino_Y)\n    predicoes_Y = dtc_entropy.predict(teste_X)\n    \n    \n\n    acc_global, acc_grupos = criar_acuracias(predicoes_Y, teste_Y, n_atribs)\n    revocacao = recall_score(teste_Y, predicoes_Y, average = None)\n    precisao = precision_score(teste_Y, predicoes_Y, average=None)\n    f1score = f1_score(teste_Y, predicoes_Y, average = None)\n    \n    array_acc_global.append(acc_global)\n    array_acc_grupos.append(acc_grupos)\n    array_revocacao.append(revocacao)\n    array_precisao.append(precisao)\n    array_f1score.append(f1score)\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\ndp_acc_global = np.std( np.array(array_acc_global) )\n\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\n\nmedia_revocacao = np.mean( np.array(array_revocacao) , axis = 0)\ndp_revocacao = np.std( np.array(array_revocacao) , axis = 0)\n\nmedia_precisao = np.mean( np.array(array_precisao) , axis = 0)\ndp_precisao = np.std( np.array(array_precisao) , axis = 0)\n\nmedia_f1score = np.mean( np.array(array_f1score) , axis = 0)\ndp_f1score = np.std( np.array(array_f1score) , axis = 0)\n\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint()\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\nprint(\"Valor médio revocação por grupo:\",media_revocacao)\nprint(\"Desvio Padrão revocação por grupo:\", dp_revocacao)\nprint()\nprint(\"Valor médio precisão por grupo:\",media_precisao)\nprint(\"Desvio Padrão precisão por grupo:\", dp_precisao)\nprint()\nprint(\"Valor médio f1_score por grupo:\",media_f1score)\nprint(\"Desvio Padrão f1_score por grupo:\", dp_f1score)\nprint()\nprint()\nprint()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "text": "------------- 1-NN | euclidiana -------------\nValor médio acurácia global: 0.6216450216450217\nDesvio Padrão acurácia global: 0.11448477351378927\n\nValor médio acurácia por grupo: [0.51904401 0.72133894]\nDesvio Padrão acurácia por grupo: [0.22352414 0.1688515 ]\n\nValor médio revocação por grupo: [0.51904401 0.72133894]\nDesvio Padrão revocação por grupo: [0.22352414 0.1688515 ]\n\nValor médio precisão por grupo: [0.66332307 0.61218281]\nDesvio Padrão precisão por grupo: [0.24442225 0.10770294]\n\nValor médio f1_score por grupo: [0.55304492 0.65061688]\nDesvio Padrão f1_score por grupo: [0.20324906 0.1026875 ]\n\n\n\n------------- 5-NN | euclidiana -------------\nValor médio acurácia global: 0.7610389610389611\nDesvio Padrão acurácia global: 0.05154242793467436\n\nValor médio acurácia por grupo: [0.79402958 0.73603452]\nDesvio Padrão acurácia por grupo: [0.15402846 0.13877755]\n\nValor médio revocação por grupo: [0.79402958 0.73603452]\nDesvio Padrão revocação por grupo: [0.15402846 0.13877755]\n\nValor médio precisão por grupo: [0.75059524 0.80081169]\nDesvio Padrão precisão por grupo: [0.11389935 0.11936657]\n\nValor médio f1_score por grupo: [0.75830784 0.7496912 ]\nDesvio Padrão f1_score por grupo: [0.08452772 0.05396808]\n\n\n\n------------- 1-NN | mahalanobis -------------\nValor médio acurácia global: 0.6311688311688313\nDesvio Padrão acurácia global: 0.10343603041167074\n\nValor médio acurácia por grupo: [0.54098485 0.72364663]\nDesvio Padrão acurácia por grupo: [0.19642628 0.16273887]\n\nValor médio revocação por grupo: [0.54098485 0.72364663]\nDesvio Padrão revocação por grupo: [0.19642628 0.16273887]\n\nValor médio precisão por grupo: [0.6715404  0.62145202]\nDesvio Padrão precisão por grupo: [0.2351671  0.09440836]\n\nValor médio f1_score por grupo: [0.57631413 0.65646892]\nDesvio Padrão f1_score por grupo: [0.17852188 0.09139512]\n\n\n\n------------- 5-NN | mahalanobis -------------\nValor médio acurácia global: 0.7658008658008658\nDesvio Padrão acurácia global: 0.04429356334872537\n\nValor médio acurácia por grupo: [0.80402958 0.73603452]\nDesvio Padrão acurácia por grupo: [0.13690937 0.13877755]\n\nValor médio revocação por grupo: [0.80402958 0.73603452]\nDesvio Padrão revocação por grupo: [0.13690937 0.13877755]\n\nValor médio precisão por grupo: [0.75416667 0.80575674]\nDesvio Padrão precisão por grupo: [0.11326299 0.11360577]\n\nValor médio f1_score por grupo: [0.76615098 0.7526912 ]\nDesvio Padrão f1_score por grupo: [0.07092788 0.0530604 ]\n\n\n\n------------- Arvore de decisão | Gini -------------\nValor médio acurácia global: 0.7138528138528139\nDesvio Padrão acurácia global: 0.09363967587651631\n\nValor médio acurácia por grupo: [0.7141811  0.72834221]\nDesvio Padrão acurácia por grupo: [0.19421732 0.11778502]\n\nValor médio revocação por grupo: [0.7141811  0.72834221]\nDesvio Padrão revocação por grupo: [0.19421732 0.11778502]\n\nValor médio precisão por grupo: [0.71039877 0.73574315]\nDesvio Padrão precisão por grupo: [0.13264644 0.15055665]\n\nValor médio f1_score por grupo: [0.69881423 0.71669681]\nDesvio Padrão f1_score por grupo: [0.13474621 0.07760258]\n\n\n\n------------- Arvore de decisão | Entropia -------------\nValor médio acurácia global: 0.7054112554112554\nDesvio Padrão acurácia global: 0.11050605012479868\n\nValor médio acurácia por grupo: [0.75022006 0.6827664 ]\nDesvio Padrão acurácia por grupo: [0.19822926 0.18734717]\n\nValor médio revocação por grupo: [0.75022006 0.6827664 ]\nDesvio Padrão revocação por grupo: [0.19822926 0.18734717]\n\nValor médio precisão por grupo: [0.70083652 0.75461219]\nDesvio Padrão precisão por grupo: [0.16193834 0.15550602]\n\nValor médio f1_score por grupo: [0.7033069  0.69051727]\nDesvio Padrão f1_score por grupo: [0.14497908 0.1178196 ]\n\n\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}