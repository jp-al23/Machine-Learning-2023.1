{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Inicializar",
      "metadata": {
        "id": "4Ujz2VzgXj8v"
      }
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt, exp, log, pi\n\n\ndef somatorio(erros, pontos):\n  vetor_x = pontos[:, 0]\n  return np.sum(vetor_x * erros)\n\ndef criar_potencias(x, tamanho):\n  # tamanho final: (n_atributos * P) + 1\n  lista = [1]\n  try:\n    x.shape[0] == 0\n  except:\n    x = np.array([x])\n  aux = np.array(x)\n  for val in aux:\n    for pot in range(1, tamanho):\n      lista.append(val ** pot)\n  return np.array(lista)\n\ndef calcular_MSE(dataset_x, dataset_y, parametros):\n  # parametros = (n_atrib * P) + 1\n  N = dataset_x.shape[0]\n  n_atrib = dataset_x.shape[1]\n  P = (parametros.shape[0] - 1) // n_atrib\n\n  y_barra = dataset_x @ parametros.T\n  erro = dataset_y - y_barra\n  MSE = np.sum(erro**2) / (2*N)\n  return MSE\n\ndef retorna_o_mesmo(x):\n  return x\n\ndef func_logistica(x):\n  return 1 / (1 + np.exp(-x))\n\ndef deriv_func_logistica(x):\n  return func_logistica(x) * (1 - func_logistica(x))\n\ndef cross_entropy_loss(X, y, w):\n  N = X.shape[0]\n  soma = 0\n  for i in range(0, N):\n    soma -= ( y[i] * log( func_logistica( w @ X[i] ) ) + (1 - y[i]) * log( 1 - func_logistica( w @ X[i] ) ) ) / N\n  return soma\n\ndef cross_entropy_loss_multiclasse(X, y_real, W):\n  y_pred = softmax( X @ W.T )\n  epsilon = 0.000000001\n  N = y_real.shape[0]\n  y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n  return - (np.sum(y_real * np.log(y_pred))) / N\n\ndef erro_reg_logistica(y, w, X):\n  # y = (N, 1)\n  # X = (N, M+1)\n  # w = (M+1, 1)\n  vetorizar = np.vectorize(func_logistica)\n\n  return y - vetorizar( w @ X.T )\n\ndef softmax(y_pred):\n  exp_pontuacoes = np.exp(y_pred)\n  return (exp_pontuacoes /  np.sum(np.atleast_2d(exp_pontuacoes), axis=1, keepdims = True))\n\n\ndef k_fold(X, Y, k):\n  n,m = X.shape\n  ordenacao = np.arange(n)\n  np.random.shuffle(ordenacao)\n  saida = []\n  intervalo = n // k\n  grupos_X = []\n  grupos_Y = []\n  for i in range(k):\n    grupos_X.append( X[ordenacao % k == i] )\n    grupos_Y.append( Y[ordenacao % k == i] )\n\n  return grupos_X, grupos_Y\n\n\ndef criar_estatisticas(y_pred, y_real, K):\n  iguais = y_pred == y_real\n  n = y_real.shape[0]\n  acuracia_global = np.sum(iguais) / n\n  acuracia_grupos = []\n  for i in range(K):\n    acuracia_grupos.append( np.sum( iguais[y_real == i]) / np.sum(y_real == i))\n  return (acuracia_global, acuracia_grupos)\n  \n",
      "metadata": {
        "id": "dPFaGyZJXfUB",
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Normalização",
      "metadata": {
        "id": "eyjk6K4lXnHa"
      }
    },
    {
      "cell_type": "code",
      "source": "def normalizar(M):\n  M_min = np.min(M, axis = 0)\n  M_max = np.max(M, axis = 0)\n  X = (M - M_min) / (M_max - M_min)\n  return (X, M_min, M_max)\n\ndef normalizar2(M, M_min, M_max):\n  X = (M - M_min) / (M_max - M_min)\n  return (X, M_min, M_max)\n\ndef desnormalizar(y_normalizado, y_min, y_max):\n  return y_normalizado * (y_max - y_min) + y_min",
      "metadata": {
        "id": "0JGFu-AyXqC-",
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Regressões",
      "metadata": {
        "id": "w_8P3YreXs3q"
      }
    },
    {
      "cell_type": "code",
      "source": "def gd(pontos_x, pontos_y, alfa, qnt_iteracoes, P = 1, hiperparametro = 0, tipo = \"linear\", plotar = False):\n  if tipo not in [\"linear\", \"func_log\", \"softmax\"]:\n    raise (\"Tipo indefinido, os tipos disponíveis são: linear, func_log, softmax\")\n  n = pontos_x.shape[0]\n  m = pontos_x.shape[1]\n  try: K = pontos_y.shape[1]\n  except: K = 1\n\n  pontos_y = np.atleast_2d(pontos_y) # (n, K)\n  X = np.array([criar_potencias(i,P+1) for i in pontos_x]) # (n, P*m+1)\n\n  estimacoes_y = np.zeros(shape = (n,K)) # (n,K)\n  erros_y = np.zeros(shape = (n,K)) # (n,K)\n  W = np.ones(shape = (K, P * m + 1)) # (K, P*m+1)\n  t = 0\n\n  historico_custo = []\n  dict_funcoes = {\"linear\": retorna_o_mesmo, \"func_log\": func_logistica, \"softmax\": softmax}\n  dict_custos = {\"linear\": calcular_MSE, \"func_log\": cross_entropy_loss, \"softmax\": cross_entropy_loss_multiclasse}\n\n  f = dict_funcoes[tipo]\n\n  \n  for _ in range(qnt_iteracoes):\n    t = t + 1\n\n    estimacoes_y = f(X @ W.T) # (n, K)\n    erros_y = pontos_y - estimacoes_y\n\n    if plotar:\n      custo = dict_custos[tipo]\n      historico_custo.append( custo(X, pontos_y, W) )\n\n    if K > 1:\n      for k in range(K):\n        W[k] = W[k] + alfa * (np.sum((erros_y[:,k] * X.T).T,axis = 0)) / n - hiperparametro * W[k]\n    else:\n      W = W + alfa * (np.sum((erros_y.T @ X),axis = 0) / n - hiperparametro * W)\n\n  if plotar: \n    plt.plot(range(qnt_iteracoes), historico_custo)\n    plt.show()\n  return W\n\n\ndef sgd(pontos_x, pontos_y, alfa, qnt_iteracoes, P = 1, hiperparametro = 0, tipo = \"linear\", plotar = False):\n  if tipo not in [\"linear\", \"func_log\", \"softmax\"]:\n    raise (\"Tipo indefinido, os tipos disponíveis são: linear, func_log, softmax\")\n  n = pontos_x.shape[0]\n  m = pontos_x.shape[1]\n  try: K = pontos_y.shape[1]\n  except: K = 1\n  # pontos_x (n,m)\n  # pontos_y (n,K)\n\n  X = np.array([criar_potencias(i,P+1) for i in pontos_x]) # (n, P*m+1)\n\n  estimacoes_y = np.zeros(shape = (n,K)) # (n,K)\n  erros_y = np.zeros(shape = (n,K)) # (n,K)\n  W = np.ones(shape = (K, P * m + 1)) # (K, P*m+1)\n  t = 0\n\n  historico_custo = []\n  dict_funcoes = {\"linear\": retorna_o_mesmo, \"func_log\": func_logistica, \"softmax\": softmax}\n  dict_custos = {\"linear\": calcular_MSE, \"func_log\": cross_entropy_loss, \"softmax\": cross_entropy_loss_multiclasse}\n\n  f = dict_funcoes[tipo]\n  \n  for _ in range(qnt_iteracoes):\n    for i in range(n):\n      t = t + 1\n    \n      estimacoes_y[i] = f(X[i] @ W.T)\n      erros_y[i] = pontos_y[i] - estimacoes_y[i]\n\n      if K > 1:\n        for k in range(K):\n          W[k] = W[k] + alfa * (erros_y[i,k]/n * X[i] - hiperparametro * W[k])\n      else:\n        W = W + alfa * (erros_y[i]/n * X[i] - hiperparametro * W)\n\n    if plotar:\n      custo = dict_custos[tipo]\n      historico_custo.append( custo(X, pontos_y, W) )\n\n  if plotar: \n    plt.plot(range(qnt_iteracoes), historico_custo)\n    plt.show()\n  return W\n\n\ndef ols(vetor_x, vetor_y, P = 1, hiperparametro = 0):\n  m = vetor_x.shape[1]\n  n = vetor_x.shape[0]\n  X = np.array([criar_potencias(i,P+1) for i in vetor_x]) # (n, P*m + 1)\n\n  W = (np.linalg.inv(X.T @ X + hiperparametro * np.eye((P * m + 1)))) @ X.T @ vetor_y\n  \n  return W.T",
      "metadata": {
        "id": "Wjoiq8QBXsft",
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Classificadores estatísticos",
      "metadata": {
        "id": "-bMGiZjM-zia"
      }
    },
    {
      "cell_type": "code",
      "source": "def matriz_desvios(x, media):\n  desvio = np.atleast_2d(x-media)\n  matriz_dev = desvio.T @ desvio\n  return matriz_dev\n  \ndef gerar_mat_cov(X):\n  n, p = X.shape\n  media = np.mean(X, axis=0)\n  vetor_matrizes = np.array([ matriz_desvios(X[i], media) for i in range(n)])\n  return np.sum(vetor_matrizes, axis = 0) / (n-1)\n\ndef variancia(matriz):\n  n,m = matriz.shape\n  medias = np.mean(matriz, axis = 0)\n  desvios = matriz - medias\n  return np.sum(desvios * desvios, axis = 0) / (n - 1)\n\n\nclass Classificadores_Est:\n  def __init__(self, dataset_x, dataset_y):\n    self.X = dataset_x\n    self.Y = dataset_y\n    self.N = dataset_x.shape[0]\n    try: self.M = dataset_x.shape[1]\n    except: self.M = 1\n    try: self.K = len(np.unique(dataset_y))\n    except: self.K = 1\n    self.grupos = [dataset_x[dataset_y == i] for i in np.unique(dataset_y)]\n    self.N_classes = np.array([len(i) for i in self.grupos])\n    self.medias = np.array([ np.mean(i, axis = 0) for i in self.grupos ])\n    self.matriz_covariancia = np.array([ gerar_mat_cov(self.grupos[i]) for i in range(self.K) ])\n    self.covariancia_colunas = np.array([ i.diagonal() for i in self.matriz_covariancia]) #!\n\n\n\n\n  def discriminante_gaussiano(self, teste_x, probabilidades = \"equiprovaveis\"):\n    if probabilidades == \"equiprovaveis\": \n      p = np.ones(self.K) * (1/self.K)\n\n    t_N, t_M = teste_x.shape\n\n    # desvio = (t_N, M)\n    # matriz_covariancia = (M, M)\n\n    epsilon = 0.000000001\n    saida = []\n    for k in range(self.K):\n      arg1 = log(np.linalg.det(self.matriz_covariancia[k]) + epsilon) / 2\n      desvio = teste_x - self.medias[k]\n      arg2 = []\n      for i in range(t_N):\n        arg2.append((desvio[i] @ np.linalg.inv(self.matriz_covariancia[k] + np.eye(self.M) * epsilon) @ desvio[i].T) / 2)\n      arg2 = np.array(arg2)\n      arg3 = log(p[k] + epsilon)\n      saida.append(- arg1 - arg2 + arg3)\n    \n    return np.argmax(np.array(saida).T, axis = 1)\n\n  def naive_bayes_gaussiano(self, teste_x, probabilidades = \"equiprovaveis\"):\n    if probabilidades == \"equiprovaveis\": \n      p = np.ones(self.K) * (1/self.K)\n\n    t_N, t_M = teste_x.shape\n\n    epsilon = 0.000000001\n    saida = []\n    for k in range(self.K):\n      arg1 = log(p[k] + epsilon)\n      arg2 = np.sum(np.log(self.covariancia_colunas[k]*2*pi+epsilon)) / 2\n      desvio = teste_x - self.medias[k]\n      arg3 = np.sum(desvio * desvio / self.covariancia_colunas[k], axis = 1) / 2\n      saida.append(arg1 - arg2 - arg3)\n    \n    return np.argmax(np.array(saida).T, axis = 1)\n  \n \n",
      "metadata": {
        "id": "cbfJrRTi-y8i",
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Funcoes para plotagem",
      "metadata": {
        "id": "H7wWSsuVXzDY"
      }
    },
    {
      "cell_type": "code",
      "source": "def plotar_regressao(dataset, parametros):\n  dataset_x = dataset[:,:-1]\n  dataset_y = dataset[:,-1]\n  min_x = min(dataset_x)\n  max_x = max(dataset_x)\n  P = parametros.shape[0]\n  \n  # Parametros (1, P)\n  intervalos_x = np.linspace(min_x, max_x, 100) # (1,100)\n  X = np.array([criar_potencias(i,P) for i in intervalos_x]) # (100, P)\n  intervalos_y = parametros @ X.T\n\n  \n\n  # Plotando os pontos\n  plt.plot(dataset_x,dataset_y,'o')\n\n  # Plotando a reta\n  plt.plot(intervalos_x,intervalos_y)\n  plt.show()\n\ndef plotar_regressao_2atributos(dataset, parametros):\n  dataset_x = dataset[:,0]\n  dataset_y = dataset[:,1]\n  min_x = min(dataset_x)\n  max_x = max(dataset_x)\n  min_y = min(dataset_y)\n  max_y = max(dataset_y)\n  N = dataset_x.shape[0]\n  P = 1\n\n  \n  # Parametros (1, P)\n  intervalos_x = np.linspace(min_x, max_x, 100) # (1,100)\n  X = np.array([criar_potencias(i,P+1) for i in intervalos_x]) # (100, P)\n  intervalos_y = X @ parametros[:2]\n\n  intervalos_x = intervalos_x\n  intervalos_y = intervalos_y\n\n  # Plotando os pontos\n  plt.plot(dataset_x,dataset_y,'o')\n\n  # Plotando a reta\n  \n  plt.plot(intervalos_x,intervalos_y * (max_y - min_y))\n  plt.show()",
      "metadata": {
        "id": "Jr4ZTUX7XyvU",
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Primeira Questão",
      "metadata": {
        "id": "ze__eGr-sikZ"
      }
    },
    {
      "cell_type": "code",
      "source": "dataset_q1 = np.genfromtxt('./breastcancer.csv', delimiter=',')\ndataset_X = dataset_q1[:,:-1]\ndataset_Y = dataset_q1[:,-1]\n\ngrupos_X, grupos_Y = k_fold(dataset_X, dataset_Y, 10)\nK = len(np.unique(dataset_Y))\n\n# GD\nprint(\"------------- GD -------------\")\narray_acc_global = []\narray_acc_grupos = []\nfor k in range(10):\n  treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n  treino_Y = np.atleast_2d(np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])).T\n  teste_X = grupos_X[k]\n  teste_Y = grupos_Y[k]\n\n  treinoX_norm, min_X, max_X = normalizar(treino_X)\n  testeX_norm, *_ = normalizar2(teste_X, min_X, max_X)\n\n  # 0.8\n  params = gd(treinoX_norm, treino_Y, 0.8, 2000, tipo = \"func_log\")\n\n  X = np.array([criar_potencias(i,1+1) for i in testeX_norm])\n  predicoes_Y = (func_logistica( X @ params.T ) > 0.5).astype(int)\n  predicoes_Y = np.atleast_2d(predicoes_Y)\n  teste_Y = np.atleast_2d(teste_Y).T\n  iguais = predicoes_Y == teste_Y\n  acc_global, acc_grupos = criar_estatisticas(predicoes_Y, teste_Y, K)\n  array_acc_global.append(acc_global)\n  array_acc_grupos.append(acc_grupos)\n\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_global = np.std( np.array(array_acc_global) )\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\n\n\n# Discriminante Gaussiano\nprint(\"------------- Discriminante Gaussiano -------------\")\narray_acc_global = []\narray_acc_grupos = []\nfor k in range(10):\n  treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n  treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])\n  teste_X = grupos_X[k]\n  teste_Y = grupos_Y[k]\n  \n  n = teste_X.shape[0]\n\n  modelo = Classificadores_Est(treino_X, treino_Y)\n  predicoes_Y = modelo.discriminante_gaussiano(teste_X)\n  iguais = predicoes_Y == teste_Y\n  acc_global, acc_grupos = criar_estatisticas(predicoes_Y, teste_Y, K)\n  array_acc_global.append(acc_global)\n  array_acc_grupos.append(acc_grupos)\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_global = np.std( np.array(array_acc_global) )\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\n\n\n# Naive Bayes Gaussiano\nprint(\"------------- Naive Bayes Gaussiano -------------\")\narray_acc_global = []\narray_acc_grupos = []\nfor k in range(10):\n  treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n  treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])\n  teste_X = grupos_X[k]\n  teste_Y = grupos_Y[k]\n  \n  n = teste_X.shape[0]\n\n  modelo = Classificadores_Est(treino_X, treino_Y)\n  predicoes_Y = modelo.naive_bayes_gaussiano(teste_X)\n  iguais = predicoes_Y == teste_Y\n  acc_global, acc_grupos = criar_estatisticas(predicoes_Y, teste_Y, K)\n  array_acc_global.append(acc_global)\n  array_acc_grupos.append(acc_grupos)\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_global = np.std( np.array(array_acc_global) )\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\n\n\n'''\nGD foi o melhor pra predizer as classes considerando a acurácia global, além de ser o melhor modela para \npredizer a primeira classe\n\nDiscriminante Gaussiano teve a menor acurácia global, entretanto ele foi o melhor modelo para classficar a\nsegunda classe\n\nNaive Bayes teve uma boa acurácia global, mas ele não apresenta nenhuma vantagem de acurácia global ou \nacurácia por grupos em comparação aos outros modelos\n\nUma boa estratégia para esse dataset seria utilizar da Regressão Logística pra a predição da classe 1, e usar o\nDiscriminante Gaussiano para a predição da classe 2\n'''",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "6Nv-acubsiVp",
        "outputId": "bcc9a9b3-9209-4e36-f7de-959bdae1afba",
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "text": "------------- GD -------------\nValor médio acurácia global: 0.9754385964912281\nValor médio acurácia por grupo: [0.99161765 0.94812522]\nDesvio Padrão acurácia global: 0.02246710258748368\nDesvio Padrão acurácia por grupo: [0.01839176 0.04497256]\n\n------------- Discriminante Gaussiano -------------\nValor médio acurácia global: 0.875187969924812\nValor médio acurácia por grupo: [0.80399225 0.9962963 ]\nDesvio Padrão acurácia global: 0.038904477016405516\nDesvio Padrão acurácia por grupo: [0.0652137  0.01111111]\n\n------------- Naive Bayes Gaussiano -------------\nValor médio acurácia global: 0.9350250626566415\nValor médio acurácia por grupo: [0.95738221 0.89635769]\nDesvio Padrão acurácia global: 0.037619091449450935\nDesvio Padrão acurácia por grupo: [0.02951596 0.07744559]\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nGD foi o melhor pra predizer as classes considerando a acurácia global, além de ser o melhor modela para \\npredizer a primeira classe\\n\\nDiscriminante Gaussiano teve a menor acurácia global, entretanto ele foi o melhor modelo para classficar a\\nsegunda classe\\n\\nNaive Bayes teve uma boa acurácia global, mas ele não apresenta nenhuma vantagem de acurácia global ou \\nacurácia por grupos em comparação aos outros modelos\\n\\nUma boa estratégia para esse dataset seria utilizar da Regressão Logística pra a predição da classe 1, e usar o\\nDiscriminante Gaussiano para a predição da classe 2\\n'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Segunda Questão",
      "metadata": {
        "id": "kxFDDFBg2UOZ"
      }
    },
    {
      "cell_type": "code",
      "source": "dataset_q2 = np.genfromtxt('./vehicle.csv', delimiter=',')\ndataset_X = dataset_q2[:,:-1]\ndataset_Y = dataset_q2[:,-1]\n\ngrupos_X, grupos_Y = k_fold(dataset_X, dataset_Y, 10)\nK = len(np.unique(dataset_Y))\n\n# GD\nprint(\"------------- GD -------------\")\narray_acc_global = []\narray_acc_grupos = []\nfor k in range(10):\n  treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n  treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:]).astype(int)\n  treino_Y = np.array([ np.eye(K)[i] for i in treino_Y ])\n  teste_X = grupos_X[k]\n  teste_Y = grupos_Y[k].astype(int)\n\n  treinoX_norm, min_X, max_X = normalizar(treino_X)\n  testeX_norm, *_ = normalizar2(teste_X, min_X, max_X)\n\n  params = gd(treinoX_norm, treino_Y, 0.8, 6000, tipo = \"softmax\")\n\n  X = np.array([criar_potencias(i,1+1) for i in testeX_norm])\n  predicoes_Y = softmax( X @ params.T )\n  predicoes_Y = np.atleast_2d(predicoes_Y)\n  predicoes_Y = np.argmax(predicoes_Y,axis = 1)\n\n  teste_Y = np.atleast_2d(teste_Y).astype(int)\n  iguais = predicoes_Y == teste_Y\n  acc_global, acc_grupos = criar_estatisticas(predicoes_Y, teste_Y, K)\n  array_acc_global.append(acc_global)\n  array_acc_grupos.append(acc_grupos)\n\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_global = np.std( np.array(array_acc_global) )\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\n\n\n# Discriminante Gaussiano\nprint(\"------------- Discriminante Gaussiano -------------\")\narray_acc_global = []\narray_acc_grupos = []\nfor k in range(10):\n  treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n  treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])\n  teste_X = grupos_X[k]\n  teste_Y = grupos_Y[k]\n  \n  n = teste_X.shape[0]\n\n  modelo = Classificadores_Est(treino_X, treino_Y)\n  predicoes_Y = modelo.discriminante_gaussiano(teste_X)\n  iguais = predicoes_Y == teste_Y\n  acc_global, acc_grupos = criar_estatisticas(predicoes_Y, teste_Y, K)\n  array_acc_global.append(acc_global)\n  array_acc_grupos.append(acc_grupos)\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_global = np.std( np.array(array_acc_global) )\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\n\n\n# Naive Bayes Gaussiano\nprint(\"------------- Naive Bayes Gaussiano -------------\")\narray_acc_global = []\narray_acc_grupos = []\nfor k in range(10):\n  treino_X = np.concatenate( grupos_X[:k] + grupos_X[k+1:])\n  treino_Y = np.concatenate( grupos_Y[:k] + grupos_Y[k+1:])\n  teste_X = grupos_X[k]\n  teste_Y = grupos_Y[k]\n  \n  n = teste_X.shape[0]\n\n  modelo = Classificadores_Est(treino_X, treino_Y)\n  predicoes_Y = modelo.naive_bayes_gaussiano(teste_X)\n  iguais = predicoes_Y == teste_Y\n  acc_global, acc_grupos = criar_estatisticas(predicoes_Y, teste_Y, K)\n  array_acc_global.append(acc_global)\n  array_acc_grupos.append(acc_grupos)\n\nmedia_acc_global = np.mean( np.array(array_acc_global) )\nmedia_acc_grupos = np.mean( np.array(array_acc_grupos) , axis = 0)\ndp_acc_global = np.std( np.array(array_acc_global) )\ndp_acc_grupos = np.std( np.array(array_acc_grupos) , axis = 0)\nprint(\"Valor médio acurácia global:\", media_acc_global)\nprint(\"Valor médio acurácia por grupo:\",media_acc_grupos)\nprint(\"Desvio Padrão acurácia global:\", dp_acc_global)\nprint(\"Desvio Padrão acurácia por grupo:\", dp_acc_grupos)\nprint()\n\n\n'''\nO modelo GD mostrou ser bem eficiente na classificação da primeira e última classe (porém, menos que o discriminante \ngaussiano), entretanto é importante destacar o seu alto desvio padrão da acurácia global, isso mostra que o modelo \né muito instável e pode ter resultados bem diferentes dependendo do conjunto de dados\n\nO modelo do Discriminante Gaussiano é sem dúvidas o melhor modelo para este dataset entre os três escolhidos, sua\nacurácia global é a maior dos três, além da acurácia de cada grupo também ser maior entre todos os modelos. Além \ndisso, ele não possui o problema de instabilidade que o modelo GD possui\n\no modelo de Naives Bayes Gaussiano teve uma baixíssima acurácia global e foi péssimo em classificar o primeiro grupo,\nele não possui nenhuma vantagem para ser utilizado nesse dataset\n\nVale destacar que, nesse dataset, os modelos tiveram dificuldade de classificar os grupos 2 e 3, muito provavelmente\nporque essas duas classes devem possuir características semelhantes.\n'''",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JRl2hDB2T8k",
        "outputId": "4c8d9810-d720-435b-bddd-0b61844591b4",
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "text": "------------- GD -------------\nValor médio acurácia global: 65.0\nValor médio acurácia por grupo: [0.91662628 0.57434889 0.63321309 0.97164048]\nDesvio Padrão acurácia global: 2.280350850198276\nDesvio Padrão acurácia por grupo: [0.05500565 0.11145823 0.12209297 0.02880608]\n\n------------- Discriminante Gaussiano -------------\nValor médio acurácia global: 0.8511484593837535\nValor médio acurácia por grupo: [0.97840909 0.73904816 0.69945526 0.991     ]\nDesvio Padrão acurácia global: 0.03707131319395602\nDesvio Padrão acurácia por grupo: [0.0350476  0.11177631 0.07351946 0.01813836]\n\n------------- Naive Bayes Gaussiano -------------\nValor médio acurácia global: 0.4588235294117647\nValor médio acurácia por grupo: [0.16727221 0.42770575 0.3867778  0.88599085]\nDesvio Padrão acurácia global: 0.06724191592131634\nDesvio Padrão acurácia por grupo: [0.06423534 0.0761307  0.10812561 0.07092715]\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nO modelo GD mostrou ser bem eficiente na classificação da primeira e última classe (porém, menos que o discriminante \\ngaussiano), entretanto é importante destacar o seu alto desvio padrão da acurácia global, isso mostra que o modelo \\né muito instável e pode ter resultados bem diferentes dependendo do conjunto de dados\\n\\nO modelo do Discriminante Gaussiano é sem dúvidas o melhor modelo para este dataset entre os três escolhidos, sua\\nacurácia global é a maior dos três, além da acurácia de cada grupo também ser maior entre todos os modelos. Além \\ndisso, ele não possui o problema de instabilidade que o modelo GD possui\\n\\no modelo de Naives Bayes Gaussiano teve uma baixíssima acurácia global e foi péssimo em classificar o primeiro grupo,\\nele não possui nenhuma vantagem para ser utilizado nesse dataset\\n\\nVale destacar que, nesse dataset, os modelos tiveram dificuldade de classificar os grupos 2 e 3, muito provavelmente\\nporque essas duas classes devem possuir características semelhantes.\\n'"
          },
          "metadata": {}
        }
      ]
    }
  ]
}